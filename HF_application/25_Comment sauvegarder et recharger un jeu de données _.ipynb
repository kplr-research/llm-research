{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b77e20",
   "metadata": {
    "id": "z5ETACbnVSl6"
   },
   "source": [
    "## Comment utiliser les Dataframes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a433e",
   "metadata": {
    "id": "k3tmm6BHC0CJ"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"swiss_judgment_prediction\", \"all_languages\", split=\"train\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23762424",
   "metadata": {
    "id": "vaqahtkyC0CJ"
   },
   "outputs": [],
   "source": [
    "# Convert the output format to pandas.DataFrame\n",
    "dataset.set_format(\"pandas\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf41816",
   "metadata": {
    "id": "1LcypJOOC0CJ"
   },
   "outputs": [],
   "source": [
    "dataset.__getitem__(0)\n",
    "\n",
    "dataset.set_format(\"pandas\")\n",
    "\n",
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c5869",
   "metadata": {
    "id": "tsYr9tpZC0CK"
   },
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed2983",
   "metadata": {
    "id": "E9yD8QdqC0CK"
   },
   "outputs": [],
   "source": [
    "# How are languages distributed across regions?\n",
    "df.groupby(\"region\")[\"language\"].value_counts()\n",
    "\n",
    "# Which legal area is most common?\n",
    "df[\"legal area\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4407473",
   "metadata": {
    "id": "hUWAhi63C0CK"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pretrained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# Tokenize the `text` column\n",
    "dataset.map(lambda x : tokenizer(x[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce9550",
   "metadata": {
    "id": "u0V0zrLOC0CL"
   },
   "outputs": [],
   "source": [
    "# Reset back to Arrow format\n",
    "dataset.reset_format()\n",
    "# Now we can tokenize!\n",
    "dataset.map(lambda x : tokenizer(x[\"text\"]))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
