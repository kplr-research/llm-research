{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a171dc8",
   "metadata": {
    "id": "9jWAMNOUQ7sf"
   },
   "source": [
    "## Comment créer un Pipeline de Tokénization ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916a2bf",
   "metadata": {
    "id": "OaSkygPspj_K"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "\"I've been waiting for a HuggingFace course my whole life.\",\n",
    "\"I hate this so much!\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8590ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTr-_eOIp7FE",
    "outputId": "f3347fe8-b47d-4f9c-ca62-549be37439f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
       "array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,\n",
       "        12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
       "       [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11806818",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJFaBykGrKDR",
    "outputId": "91b0abb2-d106-4cb6-da75-edffdc7e41dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 16, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = TFAutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "outputs. last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60ca9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50VJrOaDrf3B",
    "outputId": "0ab8f8a1-32cb-4608-9c1c-e914b443c4d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-1.5606961,  1.6122813],\n",
       "       [ 4.1692314, -3.3464477]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained( checkpoint)\n",
    "outputs = model(inputs)\n",
    "\n",
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e34bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-TNYZEkrrtY",
    "outputId": "ba41e797-5c3e-4634-b715-5fc484a29d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.0195391e-02 9.5980465e-01]\n",
      " [9.9945587e-01 5.4418371e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4f8ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkE0WUwGr355",
    "outputId": "856ef79a-3cab-4b6b-de3b-0dc65deafda6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b9fc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "af7688100c894c12b0d5099714f757b2",
      "1ea26ae392214c95a6f7d1e27b4a65b8",
      "c116b998163b49faa97f5ce1e53f6f9d",
      "bf946a3b8e9b448b914b32f472dcdb8e",
      "ce2c64cc36d54078a433c99a02eab78e",
      "00f54615e6b84c7f958da56b97091eb7",
      "13f2e448a9a9409cb48eb5377390d0f0",
      "941d0ad8617248f48a7f2e3eaa7d28b7",
      "f24dc67d06454144b0466e6dd8ba8c7b",
      "a227e38dad59431ea7df3cdece251642",
      "d0b1ef399de547c2b0f1fd129507a980",
      "9d119abdb6484c0b94be90e0447855b6",
      "6bfb33c8c51e4367bd59932f534d7011",
      "5c45703c2d3d4ac0aa38c962f7c5b3ed",
      "eabe40b9258c43c7bcbaf6d60657cf86",
      "06bd085beb0b4f2aab2f24735fa2fbce",
      "2b8834f9e8df4e489e6bca250ec6895a",
      "ec9e7bfb4587451a8db57dbbd3fccde2",
      "94cc2eb4759641b2810d7b86f5e1d07c",
      "4077cfc861274f4b934eb0d249fa0311",
      "042e2368332f456c9cefb8dfd047a405",
      "63e1ef9550af45c9ad47ae29cf7ed9a4",
      "f2477841d9fe4b7cac091edd7ae3c93f",
      "d9d9ef0e25f943ba9dd9702843c3817d",
      "0a97dc3777124843848a4b61912cf9f4",
      "0f87d2dfacb84a9fa1094ea596cffe7f",
      "9b9736162c294741bd9f7d01e0cb1c60",
      "644c46272d9a4e7da41835ad1d65c67c",
      "e11b4fede93f40f796e15dc188e103c3",
      "705a2f9e6a52414f89b7103be3024c20",
      "ef84939f3bb64ef4ba1a366efbcedfde",
      "fd4f6615d52e411d969c931ef5c9f251",
      "9123ff22e22f4fa185890493be092e96",
      "9ebaa7f92c854aad8e11b58da91f4032",
      "9a72d645ddb74db29d60d1c4618bbf02",
      "7add5e1f48f548b78592f78f1246f24d",
      "cf5ed65e61aa46c59f8236016ceaedd1",
      "0df9e17c5c1749838e045393cf1caebb",
      "b98f24e01f8d486d948d69a24de2e679",
      "09b88439f8c74a8f8ed40e0ff272104f",
      "56cc808702764b89b8bce4854ab564c6",
      "198ed1a5eb5b485f83b708573302263b",
      "00095b621d5a44f89cb3b6b5aec9b6f1",
      "759940d5f97240f4bcff3d0122e2a574",
      "fdc5b6924d3845fab58655f7c41c8b02",
      "09846703cc92475cac9f02a60913f1e8",
      "96f3f6a5df9347a2874d3601878ac757",
      "cb26ead5f51a4c8ebd7daae187905bef",
      "7207fa28e58844dba7f56bfbc14a30ec",
      "763a5b09c5f349cd93ccfe5c0c854e91",
      "76c852caf5a64df28eba2064692ecaa1",
      "e05b9d8bac194d039bbc1a51b430e194",
      "797445fd50904b129e2e7c0cf1a26bce",
      "a5ed7d708ecc400cb653fe8cf3ea364d",
      "8fdaad5f0ce24219b17ceccfd8a02ad7",
      "a1c0272352694027a9b4b08f365e9a24",
      "60e57cf457d44d88baf442a130293565",
      "126d9b65bae14e3b8b8e5d44045b0032",
      "90de83f213f840808c41b35f12d3cda6",
      "a7fbc9ca375a4cc9a760f12bc6c20de2",
      "3fb0ed51ed3b478c85ce647c02846d37",
      "8706e7e6bb3a486f8072fd4b5a4a8708",
      "81a18c3c409c4f279f1cfc3fa92a2bae",
      "ea2693af47ad4f93a726f7e9d82c6d37",
      "11f90a80e2e7442e906b9d658b348959",
      "4a66b7c09f374dc99e24d67565d9c3c0"
     ]
    },
    "id": "NLq6gnyar-3g",
    "outputId": "af5a15c2-1004-40d5-8b37-46cf343f5fd4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7688100c894c12b0d5099714f757b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d119abdb6484c0b94be90e0447855b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertModel'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2477841d9fe4b7cac091edd7ae3c93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebaa7f92c854aad8e11b58da91f4032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc5b6924d3845fab58655f7c41c8b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c0272352694027a9b4b08f365e9a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bart.modeling_bart.BartModel'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "print(type(bert_model))\n",
    "\n",
    "gpt_model = AutoModel.from_pretrained(\"gpt2\")\n",
    "print(type(gpt_model))\n",
    "\n",
    "bart_model = AutoModel.from_pretrained(\"facebook/bart-base\" )\n",
    "print(type(bart_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51703d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXrIqo22sOGo",
    "outputId": "819879c8-42a9-41d8-b4e6-f5a5ff1fa11a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
      "<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\n",
      "<class 'transformers.models.bart.configuration_bart.BartConfig'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "bert_config = AutoConfig.from_pretrained(\"bert-base-cased\" )\n",
    "print(type(bert_config))\n",
    "\n",
    "gpt_config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "print(type(gpt_config))\n",
    "\n",
    "bart_config = AutoConfig.from_pretrained(\"facebook/bart-base\")\n",
    "print(type(bart_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbcb4e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjV-dTYIstF5",
    "outputId": "6adb1a3f-3a78-4f29-8754-a6070b3e7a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
    "print(type(bert_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94546052",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FgrrUgas753",
    "outputId": "4c0493f5-8130-425a-964e-abc616cb4332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Config\n",
    "\n",
    "# Create a GPT-2 configuration object from a pre-trained model\n",
    "gpt_config = GPT2Config.from_pretrained('gpt2')\n",
    "\n",
    "# Print the type of the gpt_config object\n",
    "print(type(gpt_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa2f8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwtCJ_f7tHoP",
    "outputId": "02f89a53-d15e-44ee-9a7d-f612d5935279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bart.configuration_bart.BartConfig'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartConfig\n",
    "\n",
    "bart_config = BartConfig.from_pretrained(\"facebook/bart-base\")\n",
    "print(type(bart_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e90943",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QJnNE6ktPsX",
    "outputId": "58407c95-9aa4-4a3c-cc7a-459c3e757566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
    "print(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45de038",
   "metadata": {
    "id": "T9U_LL4wtXGH"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
    "bert_model = BertModel(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715cefc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EF2aZCmZt5IB",
    "outputId": "89b09fd2-9709-4067-d85b-45b89c3526bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abddf29c",
   "metadata": {
    "id": "gxldJbNUt8of"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "#using only 10 layers instead of 12\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\", num_hidden_layers=10)\n",
    "bert_model = BertModel(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e453a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQf51n0wuAZ3",
    "outputId": "882c2e91-96f9-43e2-f689-3c63fb8f72b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-9): 10 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d9509d",
   "metadata": {
    "id": "Sq_VZHc9uEbP"
   },
   "outputs": [],
   "source": [
    "#saving a model\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
    "bert_model = BertModel(bert_config)\n",
    "\n",
    "# Training code\n",
    "\n",
    "bert_model.save_pretrained(\"my-bert-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee1797",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnpwEz-XvjpM",
    "outputId": "766a374a-6deb-41cc-c43c-297c0fa86e01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertModel\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.35.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b76cf3",
   "metadata": {
    "id": "-hdpYHkmuYV3"
   },
   "outputs": [],
   "source": [
    "#Reloading a saved model\n",
    "from transformers import BertModel\n",
    "bert_model = BertModel.from_pretrained(\"my-bert-model\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
