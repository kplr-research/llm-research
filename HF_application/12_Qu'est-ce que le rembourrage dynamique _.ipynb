{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b98c46",
   "metadata": {
    "id": "Qi7mRZ8sSXbj"
   },
   "source": [
    "## Comment Effectuer un Pr√©traitement de paires de phrases ? (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e0b96",
   "metadata": {
    "id": "_JtmPPnXBp8x"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\",\n",
    "]\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122f42d",
   "metadata": {
    "id": "WTtURq8hBp8x"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer(\"My name is Sylvain.\", \"I work at Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4684c",
   "metadata": {
    "id": "uTKrIUL2Bp8x"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer(\n",
    "    [\"My name is Sylvain.\", \"Going to the cinema.\"],\n",
    "    [\"I work at Hugging Face.\", \"This movie is great.\"],\n",
    "    padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1e549",
   "metadata": {
    "id": "SmMDh4QPBp8y"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "batch = tokenizer(\n",
    "    [\"My name is Sylvain.\", \"Going to the cinema.\"],\n",
    "    [\"I work at Hugging Face.\", \"This movie is great.\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**batch)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
