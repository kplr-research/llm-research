{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f3d724",
   "metadata": {
    "id": "8HnoYynUWfN-"
   },
   "source": [
    "## Pourquoi les tokenizers rapides sont-ils appel√©s rapides ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb63379",
   "metadata": {
    "id": "UhHMG0wODtsp"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mnli\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d9f9b",
   "metadata": {
    "id": "a-nzNJ2wDtsq"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_with_fast(examples):\n",
    "    return fast_tokenizer(\n",
    "        examples[\"premise\"], examples[\"hypothesis\"], truncation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb107f",
   "metadata": {
    "id": "sNjLj1KMDtsq"
   },
   "outputs": [],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
    "\n",
    "def tokenize_with_slow(examples):\n",
    "    return fast_tokenizer(\n",
    "        examples[\"premise\"], examples[\"hypothesis\"], truncation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ad13c",
   "metadata": {
    "id": "smXOu7XeDtsq"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d3c0f",
   "metadata": {
    "id": "foxLXaIVDtsr"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0acd3d",
   "metadata": {
    "id": "_NA_EWSuDtsr"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_fast, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503c1a9",
   "metadata": {
    "id": "IxHmsvJFDtsr"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_slow, batched=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
