{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c934bd71",
   "metadata": {
    "id": "Eeind5-TDd3Q"
   },
   "source": [
    "## Comment utiliser une Fonction Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd6b0d",
   "metadata": {
    "id": "t9rgt-BCudT5"
   },
   "source": [
    "La fonction pipeline renvoie un objet de bout en bout qui exécute une tâche NLP sur un ou plusieurs textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124499cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmonKsiDwWax",
    "outputId": "79e2b902-5d66-427d-b1f8-b1044f92888c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.66.1)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2023.11.17)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aae340",
   "metadata": {
    "id": "EqdO3stNNPeF"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f23406",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "0d9bf58964734a6c895ae1e9ff1f1289",
      "187796e1969d42ccac1f065a3357f1aa",
      "fd732de71ccd45e9ae4d7732650c0ad5",
      "e27a00361816408d8f02d57e33149960",
      "0b650878f7a943b5afc15e7ce2676888",
      "05f686513a71474db9275813d425bbbe",
      "c71f7972f7844e77b9aa70f92c2f0299",
      "72ad44cbbdc34996a9b0d94483c5473a",
      "d238b496527d4d01819ce42ff533a251",
      "bbe6e3b5a04d4a009f8fbff8638d65a3",
      "e21f998500584987afb52de8d01125f8",
      "e873e33f5664441e9cc98b0b5ec69c72",
      "23ddc4e4ff3e4d31ae5852b591e8a877",
      "75de13feeb714bbab670b0712f09b53c",
      "de8b5030a7c84ecca65af6dcac97a4b6",
      "aa103779adf4420e9a316a33800b5620",
      "9a7cf4ddd95b4e51aeae4e100a281c7c",
      "5050121daa724263aa73f958a5a220a8",
      "95f8f8ab9a8540cd8cc80888b89d78cc",
      "db4b016422ec459e8e91b459f9a8c411",
      "b36590e436ff4304a64ce8a5882a77ad",
      "613bac0f6daf42e58f1d8c4c0ac64e7a",
      "eee44c703609436995e8d661a0f2ef0e",
      "dca00b168a3844ca8db99dc3ee12a12b",
      "40947eb0e2244c4384b4496925723d2c",
      "e528ce272a294c578e9e350110daf4a7",
      "a0e432b9241546a68715e28ece9c7f3f",
      "b4687093da86429cbae30b764cb81980",
      "b6999d058d534df5a84136ea34269105",
      "542fbb1546e34a06a4759f8f6a5c762c",
      "d981c38b5c7048c88b801e24c83cbed1",
      "7f84b2916fb845a1b4664bb125e4aa33",
      "d248a26b8efe432d895fdc3ece00108d",
      "1e960db58d084c4b9d23c4274c84ed9f",
      "030247c9c07d4949a2e27682215fcf2b",
      "3df78ac8c23542d3b7441ac73266fad5",
      "648242bc380d4987a447f42e80d01b69",
      "6201aaa8c1c94120a74b463dc035f01c",
      "51ba51108f51408892ab8d1662d1d7cf",
      "70c2b170f9284f4c97e672349de849d9",
      "8566463993b34d97a75e43f2ee5aaf04",
      "ba100e4417f447a4af5f867f6be91c68",
      "edcbf09694de4d77aba7ba4e07bc0a96",
      "3e5990eb2ca4493db073d87dce27e764"
     ]
    },
    "id": "VJ5NtIcINcyf",
    "outputId": "f1523b89-a6f9-4cf0-e3c3-5f91b87434a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9bf58964734a6c895ae1e9ff1f1289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e873e33f5664441e9cc98b0b5ec69c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee44c703609436995e8d661a0f2ef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e960db58d084c4b9d23c4274c84ed9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\") # c'est un pipeline pour la classification du texte (positif/négatif)\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9ecc9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3FDTQo8vPw2",
    "outputId": "78419b79-16b4-4e83-8cf2-54a4f8f00652"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8663091063499451}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\") # c'est un pipeline pour la classification du texte (positif/négatif)\n",
    "classifier(\"J'aime bien apprendre NLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f1c5dc",
   "metadata": {
    "id": "qfmL57YGysyJ"
   },
   "source": [
    "Lorsque vous utilisez la fonction `pipeline` de la bibliothèque Hugging Face Transformers sans spécifier de modèle, elle sélectionne un modèle par défaut pour la tâche que vous avez spécifiée. Pour la tâche **\"sentiment-analysis\"**, le modèle par défaut est **`\"distilbert-base-uncased-finetuned-sst-2-english\"`**.\n",
    "\n",
    "Ce modèle est une version de DistilBERT qui a été affinée sur l'ensemble de données SST-2, une référence largement utilisée pour l'analyse des sentiments. L'ensemble de données SST-2 (Stanford Sentiment Treebank) se compose de phrases tirées de critiques de films et d'étiquettes de sentiment correspondantes. Le modèle DistilBERT est une variante plus petite, plus rapide et plus légère de BERT, conçue pour consommer moins de ressources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1aa5fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289,
     "referenced_widgets": [
      "f480201c63724cbfb8289557053a348d",
      "90e827bc80ff4878aec13e3d0e63d98b",
      "234875fc88aa4630b03d8a5eac900d29",
      "6dd65cbbd83246c2b6dfe49181badfb5",
      "58c142b2012648c8aed7294d66d7b0b7",
      "d81cd677865d46dc8d1702d518aeb893",
      "da9497b119b4495381444f20a8e4bcc5",
      "8f94db138ea241bcb5d5ca4627235999",
      "8191864f03384a8088c2c847ce91f96c",
      "20fee8754b154ae698079cfb040a37df",
      "a7c59754ffc6491aadda9b2ca9ef1c5b",
      "104cc6aa2aca429ea999941f5cf3cd98",
      "38de0f0f65eb4d2b805ffd13ea85c00a",
      "c1c5e1b7424044239a1ab46ec30ccef3",
      "2d3e933568394554a98b7358a4c7b426",
      "fd4928f30c5643f19802e40addbf55c4",
      "a25eb091d3ac40f19125c625651e7c38",
      "240341d86c5543bdb13f9b88c17a277c",
      "b195e71b09f8427f937fe28647f65eb0",
      "d61b38fff4b6458b81a2af9873cd6f09",
      "d47a7b52719c400a90d9a0d596747627",
      "531156669424400d812ed2132b2956ba",
      "e3dcec822cea4506a37499f5d40e4623",
      "c9eeff86b5e64f60b6b14b1148cbf561",
      "ab3e97411c194cc7bbb5f32c4774991f",
      "093efe532a014764bdbc1f761f57dffe",
      "d259e364beeb4ed882d48536ac58d98f",
      "00687897cc0b4144831ab8abdcfebb40",
      "767ca9fa55a74aaab4855e46fb450fda",
      "3cd1c897378e43169a0338db9054bf1e",
      "f6eb6029ec9e4eaebdd0b84412a40781",
      "aaabf645a982442989376c8d2f44e147",
      "8afb012a09634e35a566bcb1c827d37d",
      "3de1612d9ef84aa4a93eb5c3ebde017a",
      "6ae05143c37c4a09a38e3e34838d31bd",
      "627461ba656949b68bca82aca7f8688a",
      "faf972ee3f844250908d84d0e769e595",
      "149f3efa84bf43ffa545680ee4ac4a50",
      "dab2177450ec4a2db2f335b2cdf0f020",
      "470b153855ec4108a547561fb2e0116f",
      "231e8f69f01c4c1e87bfdf03aaf0b7b1",
      "0fa9858812e14f698adc546fda070062",
      "e84aba23c1c64b4c9ecd6a0b0c2afe0a",
      "522ab3019f314759af7ab40bbc502fb5",
      "97ed3e861ec74b3e89f41c45ab90875e",
      "404d00e59b48417180e75bd73141dc38",
      "9c7ee2f9271c4d248ef8a3a0ff5572a0",
      "c8e8a2e3947b4f0aae696252feb45112",
      "653294a8a33d4af7ac160752ae617e72",
      "16dcc0ed804d4039a1bfd8dde65d2073",
      "07594fe55a394661a053c76af8d09ea6",
      "63d2c48e0c714aebbdef8d86195c90b1",
      "d3930dd4ed8946e49f6f1c5696226520",
      "85f8b8abc37d4511949db3165f4ea3ef",
      "4629e8ac87194d7394055ddc98e132bb"
     ]
    },
    "id": "U0IuDfdZvmF4",
    "outputId": "96e2729d-9f02-4d41-8fb3-a27577c1bc0f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f480201c63724cbfb8289557053a348d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104cc6aa2aca429ea999941f5cf3cd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dcec822cea4506a37499f5d40e4623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de1612d9ef84aa4a93eb5c3ebde017a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ed3e861ec74b3e89f41c45ab90875e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.6052295565605164}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"tblard/tf-allocine\") # c'est un pipeline pour la classification du texte (positif/négatif)\n",
    "classifier(\"Je n'aime pas rater mes cours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863f4f1",
   "metadata": {
    "id": "GeUoc2hL1oIu"
   },
   "source": [
    "`\"tblard/tf-allocine\"` : ce modèle est spécifiquement entraîné pour l'analyse des sentiments sur les critiques de films en langue française sur la base d'une architecture de transformers, qui est connue pour son efficacité dans le traitement des tâches linguistiques. Il est conçu pour être utilisé avec TensorFlow et devrait donner de bons résultats dans la classification des sentiments des critiques de films en français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db57a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7o8roU4QwBzJ",
    "outputId": "05ec9caf-2765-42fa-cb82-885df9a4d090"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.934744656085968}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"tblard/tf-allocine\") # c'est un pipeline pour la classification du texte (positif/négatif)\n",
    "classifier(\"J'ai attendu un cours d'HuggingFace toute ma vie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8a40c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTZ8BWNcz0Na",
    "outputId": "0e51b1fe-b826-4d26-b303-3890e5886dd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9984068274497986}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"tblard/tf-allocine\") # c'est un pipeline pour la classification du texte (positif/négatif)\n",
    "classifier(\"J'adore ce film\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
