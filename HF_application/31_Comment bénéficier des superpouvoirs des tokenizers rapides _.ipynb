{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e73349e",
   "metadata": {
    "id": "8HnoYynUWfN-"
   },
   "source": [
    "## Pourquoi les tokenizers rapides sont-ils appel√©s rapides ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7446e",
   "metadata": {
    "id": "UhHMG0wODtsp"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mnli\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060dda5d",
   "metadata": {
    "id": "a-nzNJ2wDtsq"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_with_fast(examples):\n",
    "    return fast_tokenizer(\n",
    "        examples[\"premise\"], examples[\"hypothesis\"], truncation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408412c",
   "metadata": {
    "id": "sNjLj1KMDtsq"
   },
   "outputs": [],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
    "\n",
    "def tokenize_with_slow(examples):\n",
    "    return fast_tokenizer(\n",
    "        examples[\"premise\"], examples[\"hypothesis\"], truncation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b99439",
   "metadata": {
    "id": "smXOu7XeDtsq"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0285e",
   "metadata": {
    "id": "foxLXaIVDtsr"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7375c7b",
   "metadata": {
    "id": "_NA_EWSuDtsr"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_fast, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a677a",
   "metadata": {
    "id": "IxHmsvJFDtsr"
   },
   "outputs": [],
   "source": [
    "%time tokenized_datasets = raw_datasets.map(tokenize_with_slow, batched=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
