{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce37d65",
   "metadata": {
    "id": "wIlFZxUcQWxT"
   },
   "source": [
    "## Comment instancier un transformers ? (TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a5aa40",
   "metadata": {
    "id": "ARjR0uk6XJFN"
   },
   "source": [
    "![image](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a32a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7LG0myNuruJ",
    "outputId": "e32af4ec-c7bc-4f95-8b2a-008179a7e25f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_tf_bert.TFBertModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2Model.\n",
      "\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_tf_gpt2.TFGPT2Model'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartModel.\n",
      "\n",
      "All the weights of TFBartModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bart.modeling_tf_bart.TFBartModel'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert_model = TFAutoModel.from_pretrained( \"bert-base-cased\" )\n",
    "print(type(bert_model))\n",
    "\n",
    "gpt_model = TFAutoModel.from_pretrained(\"gpt2\")\n",
    "print(type(gpt_model))\n",
    "\n",
    "bart_model = TFAutoModel.from_pretrained(\"facebook/bart-base\")\n",
    "print(type(bart_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739009c",
   "metadata": {
    "id": "2pOi_cfQX0MY"
   },
   "source": [
    "![image](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/masked_modeling.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85387739",
   "metadata": {
    "id": "V0u1VYp2XwLF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263464e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjwaNbZMu4o2",
    "outputId": "b06b2a71-94b2-4ac2-cc90-c2bcd8a87928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
      "<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\n",
      "<class 'transformers.models.bart.configuration_bart.BartConfig'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "bert_config = AutoConfig.from_pretrained(\"bert-base-cased\")\n",
    "print(type(bert_config))\n",
    "\n",
    "gpt_config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "print(type(gpt_config))\n",
    "\n",
    "bart_config = AutoConfig. from_pretrained(\"facebook/bart-base\" )\n",
    "print(type(bart_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf6532",
   "metadata": {
    "id": "rE8Ccq18vLtm"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig, TFBertModel\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
    "bert_model = TFBertModel(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395a65d",
   "metadata": {
    "id": "qnfW22Fbvvke"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig, TFBertModel\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\", num_hidden_layers=10)\n",
    "bert_model = TFBertModel(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedc816",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "c28112eb2935410c81f73d97e77c65ff",
      "cb9af81e3fa74a4a89ac63446d092d03",
      "e5bd15dc79ec47fea07c83f9a5bede0e",
      "73569e4b86034cf993c604c0e050bc14",
      "bf5bf1966f714235b38ca323549134f5",
      "f44529f0936343a18598bf97bae42bfa",
      "df03ab86869342ad804e318eca3cce98",
      "0423d05819e540a4bd4e4376c3db9d43",
      "3e309b24bf1940768663bd24275e18a2",
      "168e015e691b4ab2adc91bfc626cadd2",
      "01e6cd6a905f41e79f81fcb6800353b3",
      "3ae6f9bd49c243fab7ea607225da682b",
      "787733f33c4f4df4bc8e03ef0844d2e2",
      "d08387d7a77b42e68e4b9d0e9db9f649",
      "ddd25aae14ba402081e366cba2548956",
      "c1a2474f587c43f2baed02df66d99e20",
      "56855ccc1fcf4156be1e91bd78a519c7",
      "3e23eace74634e3186cdbf847cea6a8f",
      "27b70a901bb948d28030dd172bb9cf1e",
      "7ce101c5b5484c7394b28eb9a1630608",
      "f41a4cbedd7940f99266a9ec8b73195f",
      "e774f5464e1142d39063ba73826ac6a0",
      "aed83200bc034a26ac6490faee621577",
      "908e6110e2b0403381098e0890b1b715",
      "6337d49483484c42b96bee088e7b9a4c",
      "df84fd3af6bd4bab9008d5f75fe8d519",
      "87abb2f7370640389edfb983c4ff640f",
      "73d6f76bbbf9430cb40cff3543ba5476",
      "b892ebb2e9dd4ca4a64423057116046e",
      "c37b9b154b4c4aa3907ba4179731f002",
      "9d5c126b82d742aabfa66e12072fbe65",
      "d4020f50212a4942a537b3ceb00754f5",
      "5329667c551f4917bafce0052b38c9d8",
      "cdfb5b7e31494235b12a82e461c5d4f0",
      "1b2af04aa31c47afa8ddf88e8310ef00",
      "29ff329fd2fa4bc0aa8f664f9bb97fa7",
      "c7a9daee94884668a6a42a75512e2a0e",
      "dc998d3f5206423e9ad6d2e630f57266",
      "3794dfc0731a45628ae5143bbbde68f9",
      "d4d679e980d24939ac1d3e49fc9b2e8c",
      "dc4c1dcd1f5643ed90157f3ccb62165e",
      "585121e676ad48bd92f33109a3a1deeb",
      "b676ce41cfe444ee9954d6c2b823da25",
      "e2ad59f604e34e8d90f71f062a4c79b5"
     ]
    },
    "id": "KxoJvBWvvz92",
    "outputId": "7308f982-4208-4cef-b785-55f0faf06100"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28112eb2935410c81f73d97e77c65ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae6f9bd49c243fab7ea607225da682b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed83200bc034a26ac6490faee621577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfb5b7e31494235b12a82e461c5d4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2292, 1005, 1055, 3046, 2000, 19204, 4697, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs = tokenizer(\"Let's try to tokenize!\")\n",
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8327bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MwK_NotyYbk",
    "outputId": "69316aef-9288-4b77-d934-60d97183303d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2292, 1005, 1055, 3046, 2000, 19204, 4697, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304f516",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrjRzOoSyj6E",
    "outputId": "b3e0d7d4-b791-4541-ca5b-49410299a0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['let', \"'\", 's', 'try', 'to', 'token', '##ize', '!']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer. from_pretrained( \"bert-base-uncased\" )\n",
    "tokens = tokenizer.tokenize(\"Let's try to tokenize!\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40830df7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "6b9294c3db0143e39de31bdbe5e85eb1",
      "6737bcc5b07048eeaf44d38dbf9a078c",
      "8f8ff98277c54b62b13f4c7abbcaf0e9",
      "482b67ab77bf49e889bbd377c77b5f3b",
      "bdb4a4dffd814536887c48d9bab6ad1d",
      "20c68ff7df3548379eed70f9faace786",
      "1b350927476e4e4f81babbd3a5b282d5",
      "b5329a3412ad4df2b5c254707bad141f",
      "58e22b227d964e6080da7e0f779e05bf",
      "2bf1a05b5a9d4450ad409e6a1d139d0c",
      "e55708e694084bd483e1d79ca76b21fa",
      "29b6260e7df94abc8f9c665ce896facf",
      "e3baf341e5fb4d84b9900106d1e8eec6",
      "f26b433ee67849ab91bacd8f47b09ccd",
      "b662bf0a126f48178f6d08448f7c32b9",
      "b6a4b890080e49b6990f62985eb81396",
      "cc219f06c8d24584b0dbdf07731af224",
      "795654ba954f417798d11bf450a4c3e3",
      "12402a3a0cc941c88d870042313c7657",
      "fd12341672b24d378c4e922bf03bd6b1",
      "bc170529c28048feb8c293e1bdaeab72",
      "aa7e22a632e740939d41821630dbe717",
      "ea3d4d5d73b0417fa7114f238ff708a4",
      "1a74e235d2f04f6e858f0effc96931a5",
      "d2642430df1e47cb9010436cd118be0c",
      "9fbb1d7db73649acb68bc6536ce0009c",
      "6824f6a7ebe34968baed5ec25bef32ee",
      "a0b2e815033d41beb8962af400e9027b",
      "0a09179569a74b2583bb74a8a5392fa2",
      "c8c3e8f70be44fbf909aeddc04b6656b",
      "8c2b5001315b42f291a2c7f9511f642e",
      "d6f12a09018149a2a2c958bbc423cb0b",
      "e2d215ac84444c2f86e0839932ba79b6"
     ]
    },
    "id": "lc44uGfCy5N8",
    "outputId": "3e1255f7-cd60-4483-a728-adbe605ecc80"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9294c3db0143e39de31bdbe5e85eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b6260e7df94abc8f9c665ce896facf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3d4d5d73b0417fa7114f238ff708a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁let', \"'\", 's', '▁try', '▁to', '▁to', 'ken', 'ize', '!']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v1\")\n",
    "tokens = tokenizer.tokenize(\"Let's try to tokenize!\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e33958",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O4U1t6iy8yU",
    "outputId": "5f0570b2-ebf9-4939-ef5a-3bceaca8466b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2292, 1005, 1055, 3046, 2000, 19204, 4697, 999]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokens = tokenizer.tokenize(\"Let's try to tokenize!\")\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbfbbeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uo9_DK6ozSX8",
    "outputId": "25c16be8-cd0a-4e90-d1b4-4fc40f700c08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2292, 1005, 1055, 3046, 2000, 19204, 4697, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "final_inputs = tokenizer.prepare_for_model(input_ids)\n",
    "print(final_inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d8c47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avH4AxxrzZj7",
    "outputId": "4925fd52-ee4b-4730-c66b-6363bf717e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] let's try to tokenize! [SEP]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs = tokenizer(\"Let's try to tokenize!\")\n",
    "\n",
    "print(tokenizer.decode(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092a181",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "987e7988b2024bcea2b49f1534b72d89",
      "3e8abe001445490fbe8c0fcf97c7d8ab",
      "5499d78b9c53411e9662f167e94d865a",
      "46a11ee9526045b0ae21b05dcdcf1022",
      "ff35b9852162421cbf480b0ca65373e8",
      "10641f0ede704a359badebdf440fc28f",
      "b3b8ce234f7043ba97819da85d9edc6f",
      "1a9b710ab32a47c6b7f806d8fcfb6232",
      "6f7b5a7c89034147946f6c546302834a",
      "3129b8f69f3944198a8040b5d348c068",
      "511e292aa8b94c29b923d04390751c8b",
      "adec997b2602481a92c8d76e6a824041",
      "c21c3144330a4bc0b567a181121b6af6",
      "989885f4cf7d4d899a8834ec1c87611a",
      "f12ad203d12e48be899a53a032e27c56",
      "0551f146e8b84d34b718b39381d7c608",
      "5079d2117214468c9fca947c1ad985ef",
      "e7bd4bbbcfd1415e937c55d8e5eb9633",
      "f6c1431c388f4d6aaa7c049050fa2eed",
      "bd1934aa1e4e4257b7819fb4e166dc4a",
      "2cb7e32be23846088bcac364d5e95930",
      "bf66053c99f048b6afecf5a72bdc01d6",
      "959fa07342ff476c942134f8273a2df8",
      "8d6c0a65062c4caba23b7505de9906d8",
      "966e38a2a9e34cb5876bb17c28d5b06d",
      "d229d5b032ad4abcb0992c0413c4dcbe",
      "86bc7e5aa605479ab11be6e55f6e11ad",
      "82b56adf43a3473f908ab4f07dbcfe94",
      "08d22988213e4380877857affa5f08ea",
      "c06686a7dcfa4e9f97a04c838baa0171",
      "89b420b084c948d3ab39ac90b5bdaa22",
      "27569a92bfc143748cf9058c4440486b",
      "f287dce318c3456f8bac7dae909c8e03",
      "7bf901fb4fe0464d96a4d765805bbcc7",
      "ac3357e625b34c55addb1d4c4db42280",
      "96049edafd51409c956fef8fce8520b9",
      "062126fd83e74ac3bce0fd229f7a6c4d",
      "19715a82736244a8b4b699fd8ddfaed2",
      "41d7f5bd445741458413293c564cf76b",
      "4384bb40d70e48b9afbced7409bda25c",
      "2189d8348c2d4707a44280875f0432b1",
      "7d078de43a6d4df684c2e63c97c367b5",
      "1286969293254eb89ffc67031dd1c3c6",
      "1aac1e0de64940c59a1f81b29e7873e1"
     ]
    },
    "id": "k-G42fJtzfv7",
    "outputId": "3f5e8c26-aafa-47d0-d61d-00fa672353c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987e7988b2024bcea2b49f1534b72d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adec997b2602481a92c8d76e6a824041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959fa07342ff476c942134f8273a2df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf901fb4fe0464d96a4d765805bbcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Let's try to tokenize!</s>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\" )\n",
    "inputs = tokenizer(\"Let's try to tokenize!\")\n",
    "\n",
    "print(tokenizer.decode(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c65de8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJk-s183zlFb",
    "outputId": "efcf3f3f-ebd1-4962-b669-0f122b16da72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'input_ids': [101, 2292, 1005, 1055, 3046, 2000, 19204, 4697, 999, 102],\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs = tokenizer(\"Let's try to tokenize!\")\n",
    "pprint(inputs)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
