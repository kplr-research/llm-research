{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b8c76e",
   "metadata": {
    "id": "fUUPmVBiYgcw"
   },
   "source": [
    "## Qu'est-ce que la prétokénisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ac309",
   "metadata": {
    "id": "i827_Wet2CP0"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6448b",
   "metadata": {
    "id": "M3Lt4Jde1Pvu"
   },
   "outputs": [],
   "source": [
    "! pip install datasets transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5eead",
   "metadata": {
    "id": "N31wluV_2q4T"
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizerFast\n",
    "\n",
    "# tokenizer = AutoTokenizerFast.from_pretrained('albert-base-v1’)\n",
    "\n",
    "# text = \"3.2.1: let's get started!\"\n",
    "\n",
    "# print(tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text))\n",
    "\n",
    "\n",
    "# Ces lignes donnent une erreur du type ImportError: cannot import name 'AutoTokenizerFast' from 'transformers'  due à la version utilisé\n",
    "# Version corrigés dans la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def63de",
   "metadata": {
    "id": "u4gqeVoI2e4E"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('albert-base-v1')\n",
    "\n",
    "text = \"3.2.1: let's get started!\"\n",
    "tokens = tokenizer.tokenize(text)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
